[
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 0,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 1,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 2,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 3,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 4,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 5,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 6,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 7,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 8,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 9,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 10,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 11,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 12,
        "is_independent": false
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 13,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 14,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 15,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 16,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 17,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 18,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 19,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "fact_id": 20,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "gpt4o_mini",
        "annotator": "sheza",
        "is_missing_relationship": true,
        "global_comments": "\"Running inference on a CPU with the Hugging Face Transformers library or other frameworks like Diffusers results in slower performance.\" - slower than what? missing relation: Comparison "
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 0,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 1,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 2,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 3,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 4,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 5,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 6,
        "is_independent": false
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 7,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 8,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 9,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 10,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 11,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 12,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 13,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 14,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 15,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 16,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 17,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 18,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 19,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 20,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "fact_id": 21,
        "is_independent": true
    },
    {
        "instance_id": "252",
        "model_name": "llama3.1_7b",
        "annotator": "sheza",
        "is_missing_relationship": false,
        "global_comments": ""
    }
]