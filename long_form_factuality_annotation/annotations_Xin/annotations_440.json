[
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 0,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 1,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 2,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 3,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 4,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 5,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 6,
        "is_independent": false
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 7,
        "is_independent": false
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 8,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 9,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 10,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 11,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 12,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 13,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 14,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 15,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 16,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 17,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 18,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 19,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 20,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 21,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 22,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 23,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 24,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 25,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 26,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 27,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 28,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 29,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 30,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 31,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 32,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 33,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 34,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 35,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 36,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 37,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 38,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 39,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 40,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 41,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 42,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 43,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 44,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 45,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 46,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "fact_id": 47,
        "is_independent": true
    },
    {
        "instance_id": "440",
        "model_name": "llama3.1_7b",
        "annotator": "Xin",
        "is_missing_relationship": true,
        "global_comments": "Temporal | then | important | The error between the predicted output and the actual output is then calculated using a loss function\r\nTemporal | then kicks in, where | important | The backpropagation algorithm then kicks in, where the error is propagated backwards through the network\r\nTemporal | which is then | important | This is done by computing the gradient of the loss function with respect to each weight and bias, which is then used to update the parameters using an optimization algorithm\r\n"
    }
]